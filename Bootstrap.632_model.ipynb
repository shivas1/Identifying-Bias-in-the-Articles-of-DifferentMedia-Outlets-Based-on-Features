{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/shiva/Desktop/Master_Thesis/final-data')\n",
    "data=pd.read_csv('dt_final_new_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[[\n",
    " 'label4',\n",
    " 'glove_vec300_norm', # normalize\n",
    " 'tfidf_art', # normalize\n",
    " 'negative_conc',\n",
    " 'positive_conc',\n",
    " 'weak_subj',\n",
    " 'strong_subj',\n",
    " 'hyperbolic_terms',\n",
    " 'attitude_markers',\n",
    " 'kill_verbs',\n",
    " 'bias_lexicon',\n",
    " 'action_verbs',\n",
    " 'comparative_forms',\n",
    " 'modal_adverbs',\n",
    " 'manner_adverbs',\n",
    " 'superlative_forms',\n",
    " 'assertive_verbs',\n",
    " 'factive_verbs',\n",
    " 'report_verbs',\n",
    " 'implicative_verbs',\n",
    " 'hedges',\n",
    " 'boosters',\n",
    " 'affect ',\n",
    " 'posemo ',\n",
    " 'negemo ',\n",
    " 'anx ',\n",
    " 'anger ',\n",
    " 'sad ',\n",
    " 'social ',\n",
    " 'family ',\n",
    " 'friend ',\n",
    " 'female ',\n",
    " 'male ',\n",
    " 'cogproc ',\n",
    " 'insight ',\n",
    " 'cause ',\n",
    " 'discrep ',\n",
    " 'tentat ',\n",
    " 'certain ',\n",
    " 'differ ',\n",
    " 'percept ',\n",
    " 'see ',\n",
    " 'hear ',\n",
    " 'feel ',\n",
    " 'bio ',\n",
    " 'body ',\n",
    " 'health ',\n",
    " 'sexual ',\n",
    " 'ingest ',\n",
    " 'drives ',\n",
    " 'affiliation ',\n",
    " 'achieve ',\n",
    " 'power ',\n",
    " 'reward ',\n",
    " 'risk ',\n",
    " 'focuspast ',\n",
    " 'focuspresent ',\n",
    " 'focusfuture ',\n",
    " 'relativ ',\n",
    " 'motion ',\n",
    " 'space ',\n",
    " 'time ',\n",
    " 'work ',\n",
    " 'leisure ',\n",
    " 'home ',\n",
    " 'money ',\n",
    " 'relig ',\n",
    " 'death ',\n",
    " 'informal ',\n",
    " 'swear ',\n",
    " 'netspeak ',\n",
    " 'assent ',\n",
    " 'nonflu ',\n",
    " 'filler ',\n",
    " 'pos_ADJ',\n",
    " 'pos_ADP',\n",
    " 'pos_ADV',\n",
    " 'pos_AUX',\n",
    " 'pos_DET',\n",
    " 'pos_INTJ',\n",
    " 'pos_NOUN',\n",
    " 'pos_PRON',\n",
    " 'pos_PROPN',\n",
    " 'pos_SCONJ',\n",
    " 'pos_VERB',\n",
    " 'pos_X',\n",
    " 'dep_ROOT',\n",
    " 'dep_acl',\n",
    " 'dep_acomp',\n",
    " 'dep_advcl',\n",
    " 'dep_advmod',\n",
    " 'dep_agent',\n",
    " 'dep_amod',\n",
    " 'dep_appos',\n",
    " 'dep_attr',\n",
    " 'dep_aux',\n",
    " 'dep_auxpass',\n",
    " 'dep_case',\n",
    " 'dep_cc',\n",
    " 'dep_ccomp',\n",
    " 'dep_compound',\n",
    " 'dep_conj',\n",
    " 'dep_csubj',\n",
    " 'dep_dative',\n",
    " 'dep_dep',\n",
    " 'dep_det',\n",
    " 'dep_dobj',\n",
    " 'dep_expl',\n",
    " 'dep_intj',\n",
    " 'dep_mark',\n",
    "#  'dep_meta',\n",
    " 'dep_neg',\n",
    " 'dep_nmod',\n",
    " 'dep_npadvmod',\n",
    " 'dep_nsubj',\n",
    " 'dep_nsubjpass',\n",
    " 'dep_nummod',\n",
    " 'dep_oprd',\n",
    " 'dep_parataxis',\n",
    " 'dep_pcomp',\n",
    " 'dep_pobj',\n",
    " 'dep_poss',\n",
    " 'dep_preconj',\n",
    " 'dep_predet',\n",
    " 'dep_prep',\n",
    " 'dep_prt',\n",
    " 'dep_punct',\n",
    " 'dep_quantmod',\n",
    " 'dep_relcl',\n",
    " 'dep_xcomp',\n",
    " 'ne_CARDINAL',\n",
    " 'ne_DATE',\n",
    " 'ne_EVENT',\n",
    " 'ne_FAC',\n",
    " 'ne_GPE',\n",
    " 'ne_LANGUAGE',\n",
    " 'ne_LAW',\n",
    " 'ne_LOC',\n",
    " 'ne_MONEY',\n",
    " 'ne_NORP',\n",
    " 'ne_ORDINAL',\n",
    " 'ne_ORG',\n",
    " 'ne_PERCENT',\n",
    " 'ne_PERSON',\n",
    " 'ne_PRODUCT',\n",
    " 'ne_QUANTITY',\n",
    " 'ne_TIME',\n",
    " 'ne_WORK_OF_ART',\n",
    " 'negative_conc_context',\n",
    " 'positive_conc_context',\n",
    " 'weak_subj_context',\n",
    " 'strong_subj_context',\n",
    " 'hyperbolic_terms_context',\n",
    " 'attitude_markers_context',\n",
    " 'kill_verbs_context',\n",
    " 'bias_lexicon_context',\n",
    " 'action_verbs_context',\n",
    " 'comparative_forms_context',\n",
    " 'modal_adverbs_context',\n",
    " 'manner_adverbs_context',\n",
    " 'superlative_forms_context',\n",
    " 'assertive_verbs_context',\n",
    " 'factive_verbs_context',\n",
    " 'report_verbs_context',\n",
    " 'implicative_verbs_context',\n",
    " 'hedges_context',\n",
    " 'boosters_context',\n",
    " 'affect _context',\n",
    " 'posemo _context',\n",
    " 'negemo _context',\n",
    " 'anx _context',\n",
    " 'anger _context',\n",
    " 'sad _context',\n",
    " 'social _context',\n",
    " 'family _context',\n",
    " 'friend _context',\n",
    " 'female _context',\n",
    " 'male _context',\n",
    " 'cogproc _context',\n",
    " 'insight _context',\n",
    " 'cause _context',\n",
    " 'discrep _context',\n",
    " 'tentat _context',\n",
    " 'certain _context',\n",
    " 'differ _context',\n",
    " 'percept _context',\n",
    " 'see _context',\n",
    " 'hear _context',\n",
    " 'feel _context',\n",
    " 'bio _context',\n",
    " 'body _context',\n",
    " 'health _context',\n",
    " 'sexual _context',\n",
    " 'ingest _context',\n",
    " 'drives _context',\n",
    " 'affiliation _context',\n",
    " 'achieve _context',\n",
    " 'power _context',\n",
    " 'reward _context',\n",
    " 'risk _context',\n",
    " 'focuspast _context',\n",
    " 'focuspresent _context',\n",
    " 'focusfuture _context',\n",
    " 'relativ _context',\n",
    " 'motion _context',\n",
    " 'space _context',\n",
    " 'time _context',\n",
    " 'work _context',\n",
    " 'leisure _context',\n",
    " 'home _context',\n",
    " 'money _context',\n",
    " 'relig _context',\n",
    " 'death _context',\n",
    " 'informal _context',\n",
    " 'swear _context',\n",
    " 'netspeak _context',\n",
    " 'assent _context',\n",
    " 'nonflu _context',\n",
    " 'filler _context',\n",
    " 'pos_ADJ_context',\n",
    " 'pos_ADP_context',\n",
    " 'pos_ADV_context',\n",
    " 'pos_AUX_context',\n",
    " 'pos_DET_context',\n",
    " 'pos_INTJ_context',\n",
    " 'pos_NOUN_context',\n",
    " 'pos_PRON_context',\n",
    " 'pos_PROPN_context',\n",
    " 'pos_SCONJ_context',\n",
    " 'pos_VERB_context',\n",
    " 'pos_X_context',\n",
    " 'dep_ROOT_context',\n",
    " 'dep_acl_context',\n",
    " 'dep_acomp_context',\n",
    " 'dep_advcl_context',\n",
    " 'dep_advmod_context',\n",
    " 'dep_agent_context',\n",
    " 'dep_amod_context',\n",
    " 'dep_appos_context',\n",
    " 'dep_attr_context',\n",
    " 'dep_aux_context',\n",
    " 'dep_auxpass_context',\n",
    " 'dep_case_context',\n",
    " 'dep_cc_context',\n",
    " 'dep_ccomp_context',\n",
    " 'dep_compound_context',\n",
    " 'dep_conj_context',\n",
    " 'dep_csubj_context',\n",
    " 'dep_dative_context',\n",
    " 'dep_dep_context',\n",
    " 'dep_det_context',\n",
    " 'dep_dobj_context',\n",
    " 'dep_expl_context',\n",
    " 'dep_intj_context',\n",
    " 'dep_mark_context',\n",
    "#  'dep_meta_context',\n",
    " 'dep_neg_context',\n",
    " 'dep_nmod_context',\n",
    " 'dep_npadvmod_context',\n",
    " 'dep_nsubj_context',\n",
    " 'dep_nsubjpass_context',\n",
    " 'dep_nummod_context',\n",
    " 'dep_oprd_context',\n",
    " 'dep_parataxis_context',\n",
    " 'dep_pcomp_context',\n",
    " 'dep_pobj_context',\n",
    " 'dep_poss_context',\n",
    " 'dep_preconj_context',\n",
    " 'dep_predet_context',\n",
    " 'dep_prep_context',\n",
    " 'dep_prt_context',\n",
    " 'dep_punct_context',\n",
    " 'dep_quantmod_context',\n",
    " 'dep_relcl_context',\n",
    " 'dep_xcomp_context',\n",
    " 'ne_CARDINAL_context',\n",
    " 'ne_DATE_context',\n",
    " 'ne_EVENT_context',\n",
    " 'ne_FAC_context',\n",
    " 'ne_GPE_context',\n",
    " 'ne_LAW_context',\n",
    " 'ne_LOC_context',\n",
    " 'ne_MONEY_context',\n",
    " 'ne_NORP_context',\n",
    " 'ne_ORDINAL_context',\n",
    " 'ne_ORG_context',\n",
    " 'ne_PERCENT_context',\n",
    " 'ne_PERSON_context',\n",
    " 'ne_PRODUCT_context',\n",
    " 'ne_QUANTITY_context',\n",
    " 'ne_TIME_context',\n",
    " 'ne_WORK_OF_ART_context',\n",
    " 'ne_LANGUAGE_context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['label4'], 1)\n",
    "y = df[['label4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = copy.deepcopy(x)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled['glove_vec300_norm'] = scaler.fit_transform(x_scaled[['glove_vec300_norm']])\n",
    "x_scaled['tfidf_art'] = scaler.fit_transform(x_scaled[['tfidf_art']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, \n",
    "                                                                            test_size = 0.10, random_state = 42)\n",
    "train_features1, val_features, train_labels1, val_labels = train_test_split(train_features, train_labels, \n",
    "                                                                            test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(train_features, label=train_labels, feature_names=feature_names)\n",
    "dtest = xgboost.DMatrix(test_features, label=test_labels, feature_names=feature_names)\n",
    "dtrain1 = xgboost.DMatrix(train_features1, label=train_labels1, feature_names=feature_names)\n",
    "dval = xgboost.DMatrix(val_features, label=val_labels, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "print('Training Features for final model Shape:', train_features1.shape)\n",
    "print('Training Labels for final model Shape:', train_labels1.shape)\n",
    "print('Validation Features Shape:', val_features.shape)\n",
    "print('Validation Labels Shape:', val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = len(train_labels[train_labels['label4']==0])/len(train_labels[train_labels['label4']==1])\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':14,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':\"binary:logistic\",\n",
    "    'disable_default_eval_metric': 1,\n",
    "    'seed': 42,\n",
    "    'tree_method': 'hist',\n",
    "    'learning_rate': 0.1,\n",
    "    'scale_pos_weight': scale_pos_weight\n",
    "}\n",
    "\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(predt: np.ndarray, dtrain: xgboost.DMatrix):\n",
    "    y = dtrain.get_label()\n",
    "    predt_binary = np.where(predt > 0.5, 1, 0)\n",
    "    return \"F1_score\", metrics.f1_score(y_true=y, y_pred=predt_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,8,1)\n",
    "    for min_child_weight in range(4,41,2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "start_time = time.time()\n",
    "max_f1 = float(0)\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        feval=f1_eval,\n",
    "        early_stopping_rounds = 10,\n",
    "        maximize=True)\n",
    "    \n",
    "    mean_f1 = cv_results['test-F1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-F1_score-mean'].argmax()\n",
    "    print(\"\\tF1 {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, F1: {}\".format(best_params[0], best_params[1], max_f1))\n",
    "end_time = time.time()\n",
    "print('time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(6,11,2)]\n",
    "    for colsample in [i/10. for i in range(4,11,2)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "max_f1 = float(0)\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    \n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    \n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        feval=f1_eval,\n",
    "        early_stopping_rounds = 10,\n",
    "        maximize=True)\n",
    "    \n",
    "    mean_f1 = cv_results['test-F1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-F1_score-mean'].argmax()\n",
    "    print(\"\\tF1 {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, F1: {}\".format(best_params[0], best_params[1], max_f1))\n",
    "end_time = time.time()\n",
    "print('time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "max_f1 = float(0)\n",
    "best_params = None\n",
    "\n",
    "for eta in [0.3, 0.2, 0.1, 0.01, 0.005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    params['eta'] = eta\n",
    "\n",
    "    cv_results = xgboost.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            feval=f1_eval,\n",
    "            early_stopping_rounds = 10,\n",
    "            maximize=True)\n",
    "\n",
    "    mean_f1 = cv_results['test-F1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-F1_score-mean'].argmax()\n",
    "    print(\"\\tF1 {} for {} rounds\\n\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, F1: {}\".format(best_params, max_f1))\n",
    "end_time = time.time()\n",
    "print('time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized hyper-parameters\n",
    "params = {'max_depth': 14,\n",
    " 'min_child_weight': 18,\n",
    " 'eta': 0.3,\n",
    " 'subsample': 1.0,\n",
    " 'colsample_bytree': 1.0,\n",
    " 'objective': 'binary:logistic',\n",
    " 'disable_default_eval_metric': 1,\n",
    " 'seed': 42,\n",
    " 'tree_method': 'hist',\n",
    " 'learning_rate': 0.1,\n",
    " 'scale_pos_weight': 14.253403141361257}\n",
    "num_boost_round=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_tuned_weighted = xgboost.train(\n",
    "    params,\n",
    "    dtrain1,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtrain1, 'dtrain'), (dval, 'dval')],\n",
    "    feval=f1_eval,\n",
    "    early_stopping_rounds = 10,\n",
    "    maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/shiva/Desktop/Master_Thesis/final-data')\n",
    "xgboost_tuned_weighted.save_model(\"xgboost_tuned_weighted.model\")\n",
    "#xgboost_tuned_weighted = xgboost.Booster()\n",
    "xgboost_tuned_weighted=xgboost.XGBClassifier()\n",
    "xgboost_tuned_weighted.load_model(\"xgboost_tuned_weighted.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "X = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "# Calculate a bootstrap estimate for accuracy and a 95% confidence interval\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(estimator, X, y)\n",
    "\n",
    "\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"Accuracy\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "# X = x.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "# y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "\n",
    "# Calculate a bootstrap estimate for recall and a 95% confidence interval\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(estimator, X, y, \n",
    "                                                 scoring_func=recall_score)\n",
    "\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"recall_score\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "# X = x.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "# y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "# Calculate a bootstrap estimate for precision and a 99% confidence interval\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(estimator, X, y, \n",
    "                                                 scoring_func=precision_score, \n",
    "                                                 alpha=0.01)\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"precision_score\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "# X = x.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "# y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "# Calculate a bootstrap estimate for f1-score and a 90% confidence interval\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(estimator, X, y, \n",
    "                                                 scoring_func=f1_score, \n",
    "                                                 alpha=0.1)\n",
    "\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"f1_score\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "# X = x.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "# y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "# Calculate a bootstrap estimate for Gmean-score and a 90% confidence interval\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(estimator, X, y, \n",
    "                                                 scoring_func=fowlkes_mallows_score, \n",
    "                                                 alpha=0.1)\n",
    "\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"fowlkes_mallows_score\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "\n",
    "def bootstrap_estimate_and_ci(estimator, X, y, scoring_func=None, random_seed=0, \n",
    "                              method='.632', alpha=0.05, n_splits=50):\n",
    "    scores = bootstrap_point632_score(estimator, X, y, scoring_func=scoring_func, \n",
    "                                      n_splits=n_splits, random_seed=random_seed, \n",
    "                                      method=method)\n",
    "    estimate = np.mean(scores)\n",
    "    lower_bound = np.percentile(scores, 100*(alpha/2))\n",
    "    upper_bound = np.percentile(scores, 100*(1-alpha/2))\n",
    "    stderr = np.std(scores)\n",
    "    \n",
    "    return estimate, lower_bound, upper_bound, stderr\n",
    "\n",
    "\n",
    "#================#\n",
    "#    Examples    #\n",
    "#================#\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score, fowlkes_mallows_score\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "ci_low = []\n",
    "ci_up = []\n",
    "\n",
    "# X = x.to_numpy()\n",
    "# y = y.to_numpy()\n",
    "# y = np.array([x[0] for x in y])\n",
    "\n",
    "# X, y = make_classification(n_redundant=0)\n",
    "estimator = XGBClassifier()\n",
    "\n",
    "# Calculate a bootstrap estimate for ROC AUC and a 95% confidence interval\n",
    "# It's a hack, but it's short and simple.\n",
    "cloned_estimator = clone(estimator)\n",
    "cloned_estimator.predict = cloned_estimator.predict_proba\n",
    "est, low, up, stderr = bootstrap_estimate_and_ci(cloned_estimator, X, y, \n",
    "                                                 scoring_func=roc_auc_score)\n",
    "\n",
    "print(f\"estimate: {est:.2f}, confidence interval: [{low:.2f}, {up:.2f}], \"\n",
    "      f\"standard error: {stderr:.2f}\")\n",
    "\n",
    "xg_results = pd.read_csv(\"xg_results.csv\")\n",
    "xg_results.loc[xg_results.shape[0]] = [\"roc_auc_score\", est, low, up, stderr]\n",
    "xg_results.to_csv(\"xg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
